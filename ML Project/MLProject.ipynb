{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a64b00f6-7c10-470e-ac25-3e9b7784a59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as nm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import xgboost as xgb\n",
    "import datetime as dt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "687c576c-5b19-4cf7-adf0-062b9b163dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000fd6641609c6ece5454664794f0340ad84dddce9a2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000041bdba6ecadd89a52d11886e8eaaec9325906c9723...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458908</th>\n",
       "      <td>ffff41c8a52833b56430603969b9ca48d208e7c192c6a4...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458909</th>\n",
       "      <td>ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458910</th>\n",
       "      <td>ffff9984b999fccb2b6127635ed0736dda94e544e67e02...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458911</th>\n",
       "      <td>ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf38814...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458912</th>\n",
       "      <td>fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458913 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              customer_ID  target\n",
       "0       0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...       0\n",
       "1       00000fd6641609c6ece5454664794f0340ad84dddce9a2...       0\n",
       "2       00001b22f846c82c51f6e3958ccd81970162bae8b007e8...       0\n",
       "3       000041bdba6ecadd89a52d11886e8eaaec9325906c9723...       0\n",
       "4       00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...       0\n",
       "...                                                   ...     ...\n",
       "458908  ffff41c8a52833b56430603969b9ca48d208e7c192c6a4...       0\n",
       "458909  ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fd...       0\n",
       "458910  ffff9984b999fccb2b6127635ed0736dda94e544e67e02...       0\n",
       "458911  ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf38814...       1\n",
       "458912  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...       0\n",
       "\n",
       "[458913 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels= pd.read_csv(\"train_labels.csv\")\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78f3c6ec-beab-4e45-b24e-2b71200c0ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_data=pd.DataFrame()\n",
    "data= pd.read_csv('train_data.csv',nrows=100000)\n",
    "data[\"S_2\"]=pd.to_datetime(data[\"S_2\"])\n",
    "data[\"Year-Month\"] = data[\"S_2\"].dt.to_period('M')\n",
    "data1=data.groupby('customer_ID').apply(lambda x: x.sample(n=1)).reset_index(drop = True)\n",
    "final_data=pd.concat([final_data,pd.merge(labels,data1, how= 'inner', on='customer_ID')])\n",
    "\n",
    "\n",
    "final_data\n",
    "\n",
    "final_data.to_csv(\"Final_data-Step3.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f1e0862-269f-4fbb-85a6-2291f1a7ee6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc1687f-dbb5-493a-bae4-048a56733680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp[\"S_2\"]=pd.to_datetime(temp[\"S_2\"])\n",
    "# temp[\"Year-Month\"] = temp[\"S_2\"].dt.to_period('M')\n",
    "# temp1=temp.groupby(['customer_ID','Year-Month'])\n",
    "# ttemp2 = temp1.first()\n",
    "# temp = pd.read_csv('train_data.csv',nrows=100)\n",
    "# temp.dtypes\n",
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9503f49-5883-4dc7-ae5c-893dfb7348e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c4a9495-c52d-4e73-bff9-6c0802cd9f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['customer_ID', 'D_63', 'D_64']\n"
     ]
    }
   ],
   "source": [
    "dtypes=final_data.dtypes\n",
    "\n",
    "dtypelist = list()\n",
    "\n",
    "for col in dtypes.index:\n",
    "    if dtypes[col] == 'object':\n",
    "        dtypelist.append(col)\n",
    "        \n",
    "print(dtypelist)\n",
    "\n",
    "# final_data['D_63'].value_counts()\n",
    "# final_data['D_64'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f2c95cf-200e-43dc-9458-951558c15ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1592448"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "size = final_data.size\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17eb6ca3-b0b6-4684-94ec-c8460949d44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(final_data[['D_63', 'D_64']])\n",
    "\n",
    "# Combine the one hot encoded data with the original dataframe\n",
    "final_data = pd.concat([final_data, one_hot], axis=1)\n",
    "\n",
    "# Drop the original categorical columns\n",
    "final_data.drop(['D_63', 'D_64', 'customer_ID'], axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ea3f347-9607-4845-9ab5-de5a02f0f2b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21772\\3172395271.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'object'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mdtypelist1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1525\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1527\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1528\u001b[0m             \u001b[1;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m             \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "# dtypes=final_data.dtypes\n",
    "\n",
    "# dtypelist1 = list()\n",
    "\n",
    "# for col in dtypes.index:\n",
    "#     if dtypes[col] == 'object':\n",
    "#         dtypelist1.append(col)\n",
    "        \n",
    "# print(dtypelist1)\n",
    "\n",
    "# final_data['D_64'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77eab7ed-6f92-402c-a3c3-5342da902299",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.dtypes\n",
    "\n",
    "final_data.replace('', nm.nan, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1733737-1689-4261-9a6a-310d5625c1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv(\"XGBoost_Input_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abc89fc1-1aa7-446e-a549-6ef1b8fcb31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "value = final_data['D_42'][1]\n",
    "\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e49ecc09-44fa-4f63-b260-0ab2b6083325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2017-03\n",
       "1       2017-05\n",
       "2       2017-12\n",
       "3       2017-07\n",
       "4       2017-05\n",
       "         ...   \n",
       "8289    2018-01\n",
       "8290    2017-09\n",
       "8291    2017-10\n",
       "8292    2017-11\n",
       "8293    2017-04\n",
       "Name: Year-Month, Length: 8294, dtype: period[M]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data['Year-Month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3697414-5848-41b1-85b9-400677795efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test-train-test split\n",
    "\n",
    "train_start_date = '2017-05'\n",
    "train_end_date = '2018-01'\n",
    "\n",
    "# Define the start and end dates for the test 1 set\n",
    "test_start_date = '2017-03'\n",
    "test_end_date = '2017-04'\n",
    "\n",
    "# Define the start and end dates for the test 2 setYear-Month\n",
    "test1_start_date = '2018-02'\n",
    "test1_end_date = '2018-03'\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_final_data = final_data[(final_data['Year-Month'] >= train_start_date) & (final_data['Year-Month'] <= train_end_date)]\n",
    "test_final_data = final_data[(final_data['Year-Month'] >= test_start_date) & (final_data['Year-Month'] <= test_end_date)]\n",
    "test2_final_data = final_data[(final_data['Year-Month'] >= test_start_date) & (final_data['Year-Month'] <= test_end_date) ]         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92cf40eb-a6a5-4a1b-a333-fcaf732ee8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5624\n"
     ]
    }
   ],
   "source": [
    "print(len(train_final_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63545655-7a88-444d-a159-fe9a22f2fb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final_data\n",
    "\n",
    "train_final_data['target'].dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3515557e-0ba0-485c-888f-dd8f05a36f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1106\n"
     ]
    }
   ],
   "source": [
    "print(len(test_final_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ea49a6d-852d-4d3c-88e8-e5340b877457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1106\n"
     ]
    }
   ],
   "source": [
    "print(len(test2_final_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16fb047a-0738-4411-8a92-d02cdbc1c04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>S_2</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_63_CL</th>\n",
       "      <th>D_63_CO</th>\n",
       "      <th>D_63_CR</th>\n",
       "      <th>D_63_XL</th>\n",
       "      <th>D_63_XM</th>\n",
       "      <th>D_63_XZ</th>\n",
       "      <th>D_64_-1</th>\n",
       "      <th>D_64_O</th>\n",
       "      <th>D_64_R</th>\n",
       "      <th>D_64_U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>0.922563</td>\n",
       "      <td>0.567403</td>\n",
       "      <td>0.033713</td>\n",
       "      <td>1.007497</td>\n",
       "      <td>0.005594</td>\n",
       "      <td>0.094655</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.010466</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-12</td>\n",
       "      <td>0.872014</td>\n",
       "      <td>0.007485</td>\n",
       "      <td>0.001891</td>\n",
       "      <td>0.816083</td>\n",
       "      <td>0.006484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007051</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-07-16</td>\n",
       "      <td>0.598278</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.045268</td>\n",
       "      <td>1.007780</td>\n",
       "      <td>0.008866</td>\n",
       "      <td>0.162771</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-30</td>\n",
       "      <td>0.937438</td>\n",
       "      <td>0.003936</td>\n",
       "      <td>0.003352</td>\n",
       "      <td>0.814304</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.003142</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-12</td>\n",
       "      <td>0.413310</td>\n",
       "      <td>0.003285</td>\n",
       "      <td>0.053418</td>\n",
       "      <td>0.304955</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>0.009388</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8288</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-12-21</td>\n",
       "      <td>0.305306</td>\n",
       "      <td>0.035043</td>\n",
       "      <td>0.064785</td>\n",
       "      <td>0.094911</td>\n",
       "      <td>0.509138</td>\n",
       "      <td>0.225223</td>\n",
       "      <td>0.007922</td>\n",
       "      <td>0.174662</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8289</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>0.526164</td>\n",
       "      <td>0.035330</td>\n",
       "      <td>0.714960</td>\n",
       "      <td>0.026882</td>\n",
       "      <td>0.251946</td>\n",
       "      <td>0.209647</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.007715</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8290</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-09-03</td>\n",
       "      <td>0.920667</td>\n",
       "      <td>0.009949</td>\n",
       "      <td>0.003489</td>\n",
       "      <td>1.000081</td>\n",
       "      <td>0.003225</td>\n",
       "      <td>0.144085</td>\n",
       "      <td>0.008304</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8291</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-10-26</td>\n",
       "      <td>0.854344</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>0.008311</td>\n",
       "      <td>1.006577</td>\n",
       "      <td>0.005204</td>\n",
       "      <td>0.152868</td>\n",
       "      <td>0.003385</td>\n",
       "      <td>0.007144</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8292</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-29</td>\n",
       "      <td>0.435756</td>\n",
       "      <td>0.031057</td>\n",
       "      <td>0.482063</td>\n",
       "      <td>0.027948</td>\n",
       "      <td>0.009905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003934</td>\n",
       "      <td>0.626399</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5624 rows Ã— 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target        S_2       P_2      D_39       B_1       B_2       R_1  \\\n",
       "1          0 2017-05-07  0.922563  0.567403  0.033713  1.007497  0.005594   \n",
       "2          0 2017-12-12  0.872014  0.007485  0.001891  0.816083  0.006484   \n",
       "3          0 2017-07-16  0.598278  0.000660  0.045268  1.007780  0.008866   \n",
       "4          0 2017-05-30  0.937438  0.003936  0.003352  0.814304  0.002594   \n",
       "6          0 2017-05-12  0.413310  0.003285  0.053418  0.304955  0.002316   \n",
       "...      ...        ...       ...       ...       ...       ...       ...   \n",
       "8288       1 2017-12-21  0.305306  0.035043  0.064785  0.094911  0.509138   \n",
       "8289       1 2018-01-25  0.526164  0.035330  0.714960  0.026882  0.251946   \n",
       "8290       0 2017-09-03  0.920667  0.009949  0.003489  1.000081  0.003225   \n",
       "8291       0 2017-10-26  0.854344  0.001644  0.008311  1.006577  0.005204   \n",
       "8292       0 2017-11-29  0.435756  0.031057  0.482063  0.027948  0.009905   \n",
       "\n",
       "           S_3      D_41       B_3  ...  D_63_CL  D_63_CO  D_63_CR  D_63_XL  \\\n",
       "1     0.094655  0.003162  0.010466  ...        0        1        0        0   \n",
       "2          NaN  0.007051  0.007042  ...        0        1        0        0   \n",
       "3     0.162771  0.004137  0.007301  ...        0        1        0        0   \n",
       "4          NaN  0.000545  0.003142  ...        0        1        0        0   \n",
       "6     0.415906  0.009388  0.048780  ...        0        1        0        0   \n",
       "...        ...       ...       ...  ...      ...      ...      ...      ...   \n",
       "8288  0.225223  0.007922  0.174662  ...        0        1        0        0   \n",
       "8289  0.209647  0.005900  1.007715  ...        0        1        0        0   \n",
       "8290  0.144085  0.008304  0.007060  ...        1        0        0        0   \n",
       "8291  0.152868  0.003385  0.007144  ...        0        1        0        0   \n",
       "8292       NaN  0.003934  0.626399  ...        0        1        0        0   \n",
       "\n",
       "      D_63_XM  D_63_XZ  D_64_-1  D_64_O  D_64_R  D_64_U  \n",
       "1           0        0        0       1       0       0  \n",
       "2           0        0        0       0       1       0  \n",
       "3           0        0        0       1       0       0  \n",
       "4           0        0        0       1       0       0  \n",
       "6           0        0        0       0       1       0  \n",
       "...       ...      ...      ...     ...     ...     ...  \n",
       "8288        0        0        0       0       0       1  \n",
       "8289        0        0        0       1       0       0  \n",
       "8290        0        0        0       0       0       1  \n",
       "8291        0        0        0       0       1       0  \n",
       "8292        0        0        0       0       0       1  \n",
       "\n",
       "[5624 rows x 199 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c88cd65b-2e1d-441f-882c-6d9a3b611e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.8426763110307414\n",
      "Accuracy on test data 1: 0.8426763110307414\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract the input features and target variable from the training data\n",
    "X_train = train_final_data.drop(columns=['target','S_2', 'Year-Month'])\n",
    "y_train = train_final_data['target']\n",
    "\n",
    "# Extract the input features and target variable from the test data\n",
    "X_test = test_final_data.drop(columns=['target','S_2', 'Year-Month'])\n",
    "y_test = test_final_data['target']\n",
    "\n",
    "# Extract the input features and target variable from the test data 1\n",
    "X_test1 = test2_final_data.drop(columns=['target','S_2', 'Year-Month'])\n",
    "y_test1 = test2_final_data['target']\n",
    "\n",
    "# Define the XGBoost model\n",
    "model = xgb.XGBClassifier(random_state=52)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the model on the test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on test data:\", accuracy)\n",
    "\n",
    "# Make predictions on the test data 1\n",
    "y_pred1 = model.predict(X_test1)\n",
    "\n",
    "# Evaluate the accuracy of the model on the test data 1\n",
    "accuracy1 = accuracy_score(y_test1, y_pred1)\n",
    "print(\"Accuracy on test data 1:\", accuracy1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fad9ceb-f55d-4b89-b36a-d91d35453b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1626387  0.00424849 0.00921448 0.00883168 0.00808287 0.01122728\n",
      " 0.00660475 0.00851075 0.01444073 0.00932448 0.00783467 0.0093553\n",
      " 0.0091998  0.00521929 0.00534365 0.00583465 0.00661815 0.00708495\n",
      " 0.0050751  0.00212861 0.00675377 0.00490209 0.00717978 0.00326799\n",
      " 0.01428428 0.00760644 0.00677576 0.00318214 0.00175152 0.00306725\n",
      " 0.00757013 0.00893366 0.00516434 0.0029179  0.00200098 0.00516158\n",
      " 0.00575678 0.00278079 0.00442245 0.00869351 0.00288137 0.00485144\n",
      " 0.00442572 0.00471564 0.0038928  0.00331718 0.0040894  0.00984422\n",
      " 0.00231422 0.00593374 0.00852369 0.00484426 0.00409181 0.00556565\n",
      " 0.00995853 0.00257473 0.0034214  0.00335262 0.00078181 0.00403701\n",
      " 0.00213452 0.00406884 0.00488692 0.00276116 0.00794101 0.00607152\n",
      " 0.00337992 0.0039349  0.00632035 0.00858639 0.         0.00355757\n",
      " 0.00170707 0.02281533 0.00610925 0.00412518 0.00296658 0.00713835\n",
      " 0.00173779 0.00249741 0.00353952 0.00440062 0.00698007 0.0036595\n",
      " 0.00332888 0.0011132  0.00387082 0.00268629 0.00488321 0.00366948\n",
      " 0.00429672 0.00274644 0.00546979 0.00517959 0.0027582  0.00269127\n",
      " 0.00254393 0.00273629 0.00366811 0.00485143 0.00760774 0.00717063\n",
      " 0.00302332 0.00251949 0.         0.00320647 0.0044166  0.\n",
      " 0.         0.00272968 0.00253602 0.00212102 0.00382447 0.00376803\n",
      " 0.00245679 0.00575936 0.0058068  0.00389224 0.0034167  0.00220145\n",
      " 0.00362498 0.00565713 0.00412152 0.00387821 0.00232433 0.00262227\n",
      " 0.00477726 0.00997614 0.00296459 0.00573116 0.00413233 0.00457917\n",
      " 0.0066499  0.00252197 0.00546551 0.00228914 0.00379947 0.00255028\n",
      " 0.00894921 0.00639483 0.00738172 0.00196784 0.         0.00317336\n",
      " 0.         0.         0.         0.00576423 0.00376008 0.00270796\n",
      " 0.00493481 0.         0.00246224 0.         0.00080079 0.00366237\n",
      " 0.00804384 0.00044425 0.00302218 0.00547944 0.00306812 0.00330298\n",
      " 0.00401756 0.00059382 0.0035821  0.00457866 0.00273411 0.00313053\n",
      " 0.         0.00613105 0.00399637 0.00712262 0.00407386 0.00174563\n",
      " 0.         0.01065574 0.00528219 0.00440644 0.         0.00528131\n",
      " 0.00270147 0.00466767 0.00145287 0.00229714 0.00400523 0.00181118\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.00606785 0.         0.        ]\n",
      "    feature  importance\n",
      "0       P_2    0.162639\n",
      "73     D_75    0.022815\n",
      "8      D_42    0.014441\n",
      "24      B_9    0.014284\n",
      "5       S_3    0.011227\n",
      "..      ...         ...\n",
      "142   D_108    0.000000\n",
      "70     D_73    0.000000\n",
      "104    D_87    0.000000\n",
      "108    B_31    0.000000\n",
      "195  D_64_U    0.000000\n",
      "\n",
      "[196 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Feature_Importance\n",
    "importance = model.feature_importances_\n",
    "\n",
    "print(importance)\n",
    "\n",
    "feature_importance_df = pd.DataFrame(list(zip(X_train.columns, importance)), columns=['feature', 'importance'])\n",
    "\n",
    "# sort the dataframe in descending order of importance\n",
    "feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# print the dataframe\n",
    "print(feature_importance_df)\n",
    "\n",
    "feature_importance_df.to_csv(\"Feature_Importance_1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e1d52f8-26bd-4a47-937a-de17d282a9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02936756 0.00342817 0.01087152 0.01389714 0.00532627 0.00974959\n",
      " 0.00659307 0.02499316 0.00729906 0.00631196 0.00653549 0.00705377\n",
      " 0.00460882 0.00666691 0.00560447 0.00350025 0.01191912 0.02852331\n",
      " 0.01090805 0.003406   0.00610509 0.0104621  0.0144779  0.00522925\n",
      " 0.00403794 0.01270267 0.00616485 0.00742617 0.00366866 0.00720762\n",
      " 0.00476529 0.00405162 0.00576198 0.00481099 0.00428056 0.00624297\n",
      " 0.0032061  0.00902877 0.00322555 0.00681742 0.00373821 0.00200095\n",
      " 0.00323556 0.0100659  0.00548002 0.00355718 0.00377675 0.04559926\n",
      " 0.00404742 0.00487064 0.00606404 0.00262177 0.00296716 0.00366112\n",
      " 0.00489926 0.00380222 0.         0.00607889 0.00044936 0.00475937\n",
      " 0.00442768 0.00505834 0.004437   0.00620319 0.00780143 0.00345156\n",
      " 0.00449188 0.00531604 0.00308327 0.00332847 0.01798632 0.00205782\n",
      " 0.00553811 0.01112732 0.01122383 0.00458459 0.00237779 0.01543164\n",
      " 0.00396288 0.00679526 0.00427073 0.00340503 0.00253584 0.00441491\n",
      " 0.00316062 0.0024856  0.00392787 0.00383605 0.00498916 0.00449878\n",
      " 0.00674181 0.00385971 0.00199577 0.00462402 0.00286125 0.00396715\n",
      " 0.00293714 0.00125744 0.00288923 0.00438881 0.0048545  0.00125032\n",
      " 0.00612274 0.00234069 0.         0.00582198 0.00350161 0.\n",
      " 0.         0.00344812 0.00185482 0.0048317  0.00605015 0.00534543\n",
      " 0.00314313 0.00386587 0.00489894 0.00264759 0.00438999 0.00374446\n",
      " 0.00439423 0.00476879 0.00205743 0.00413168 0.00319538 0.00264719\n",
      " 0.00648387 0.00610583 0.00360991 0.00225298 0.00458719 0.00375435\n",
      " 0.00185395 0.00505424 0.00276086 0.00079474 0.00387124 0.00253349\n",
      " 0.00346667 0.00519777 0.00363793 0.01192924 0.         0.00788736\n",
      " 0.         0.         0.         0.00395265 0.00149672 0.00516851\n",
      " 0.00364471 0.0001429  0.00173749 0.         0.00591929 0.00381724\n",
      " 0.00461018 0.02519105 0.00535757 0.00444924 0.00712089 0.0052939\n",
      " 0.00473089 0.00351402 0.00194418 0.0039812  0.00300722 0.00345919\n",
      " 0.         0.0021595  0.00531726 0.00906522 0.00372384 0.00175877\n",
      " 0.00773302 0.01047738 0.0015674  0.         0.         0.00285879\n",
      " 0.00323004 0.00492954 0.00665936 0.00292047 0.00359498 0.00425127\n",
      " 0.0041534  0.         0.00195459 0.         0.         0.\n",
      " 0.         0.         0.         0.0003741 ]\n"
     ]
    }
   ],
   "source": [
    "# set the hyperparameters\n",
    "params = {\n",
    "    'n_estimators': 300,\n",
    "    'learning_rate': 0.5,\n",
    "    'max_depth': 4,\n",
    "    'subsample': 0.5,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'scale_pos_weight': 5\n",
    "}\n",
    "\n",
    "# create the XGBClassifier object with the hyperparameters\n",
    "model1 = xgb.XGBClassifier(**params)\n",
    "\n",
    "# train the model on the training set\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# # make predictions on the test set\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# print(y_pred)\n",
    "\n",
    "importance = model1.feature_importances_\n",
    "\n",
    "print(importance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49b4947e-b99e-477e-b486-46b135f32d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     feature  importance\n",
      "0        P_2    0.162639\n",
      "73      D_75    0.022815\n",
      "8       D_42    0.014441\n",
      "24       B_9    0.014284\n",
      "5        S_3    0.011227\n",
      "..       ...         ...\n",
      "191  D_63_XZ    0.000000\n",
      "186  D_63_CL    0.000000\n",
      "194   D_64_R    0.000000\n",
      "192  D_64_-1    0.000000\n",
      "195   D_64_U    0.000000\n",
      "\n",
      "[196 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "feature_importance = pd.DataFrame(list(zip(X_train.columns, importance)), columns=['feature', 'importance'])\n",
    "\n",
    "# sort the dataframe in descending order of importance\n",
    "feature_importance = feature_importance_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# print the dataframe\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc73c516-ac6a-4581-9ef7-abaa324521b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance.to_csv(\"Feature_Importance2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5aa961ec-1659-428c-8c21-75c1c36b0c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature  importance\n",
      "0      P_2    0.162639\n",
      "73    D_75    0.022815\n",
      "8     D_42    0.014441\n",
      "24     B_9    0.014284\n",
      "5      S_3    0.011227\n",
      "..     ...         ...\n",
      "13     B_5    0.005219\n",
      "93    B_28    0.005180\n",
      "32     S_6    0.005164\n",
      "35     S_7    0.005162\n",
      "18    D_49    0.005075\n",
      "\n",
      "[65 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_selected_features = feature_importance[feature_importance['importance'] >= 0.005]\n",
    "print(df_selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f6b6558-7dc2-44d0-8f2c-fb2c088149bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.5, 1.0],\n",
       "                         'learning_rate': [0.01, 0.1],\n",
       "                         'n_estimators': [50, 100, 300],\n",
       "                         'scale_pos_weight': [1, 5, 10],\n",
       "                         'subsample': [0.5, 0.8]})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset X_train to include only selected features\n",
    "X_train_selected = X_train.loc[:, df_selected_features['feature'].tolist()]\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 300],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.5, 0.8],\n",
    "    'colsample_bytree': [0.5, 1.0],\n",
    "    'scale_pos_weight': [1, 5, 10]\n",
    "}\n",
    "\n",
    "# Create an XGBoost classifier object\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "974e3f3b-2503-4237-8eef-470dcb60b999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 4.87001438,  6.58376961,  5.40040126,  7.44230342,  5.68734579,\n",
       "         6.2300909 ,  9.31461039, 11.43909159,  9.9663856 , 12.70912414,\n",
       "        10.12870884, 12.65480161, 27.26184964, 36.82918224, 28.90752358,\n",
       "        36.25621796, 26.92090993, 35.29790478,  4.49719515,  5.79143744,\n",
       "         4.80619941,  6.08834872,  4.5770577 ,  5.92872896,  8.6633698 ,\n",
       "        11.04839993,  8.78125095, 11.57927208,  8.82455025, 11.55603123,\n",
       "        26.02121882, 35.65726843, 27.99626722, 35.83239603, 31.20142026,\n",
       "        41.81059513, 11.23974805, 11.90434184,  9.00915732, 12.03497486,\n",
       "         9.06889853, 11.92843227, 17.33994555, 22.65446143, 18.19008255,\n",
       "        23.08683472, 18.00203843, 23.66974611, 50.58684387, 67.77756066,\n",
       "        52.39643345, 71.44442849, 52.70405102, 72.93717623,  8.48674574,\n",
       "        12.08341818,  9.39201493, 11.59162741,  8.70822477, 11.47542834,\n",
       "        16.56751709, 21.64719272, 16.39411807, 23.08985319, 17.28915339,\n",
       "        24.07483945, 56.56345105, 77.4282012 , 60.21888967, 76.84266734,\n",
       "        56.70016756, 66.04461646]),\n",
       " 'std_fit_time': array([0.36239422, 0.2275108 , 0.33073594, 0.63101615, 0.60196421,\n",
       "        0.35044258, 0.37172807, 0.61944374, 0.75187636, 0.53525697,\n",
       "        0.42024105, 0.71587695, 1.28228968, 1.01503003, 0.47609926,\n",
       "        0.73764319, 0.43506176, 0.74493001, 0.24620114, 0.2614791 ,\n",
       "        0.27458969, 0.23886597, 0.15550996, 0.04964111, 0.26658285,\n",
       "        0.11052301, 0.2531844 , 0.22588151, 0.20533597, 0.12889251,\n",
       "        1.44118582, 1.7143378 , 1.00891335, 1.42656896, 3.26217078,\n",
       "        1.22198411, 1.09172423, 0.53966331, 0.38454633, 0.47285793,\n",
       "        0.59310124, 0.50345155, 0.20200343, 0.71789828, 0.57013997,\n",
       "        0.49698458, 0.58899383, 0.86220825, 1.16284722, 1.7430261 ,\n",
       "        0.52019891, 0.62690982, 1.52669929, 1.74194963, 0.17186579,\n",
       "        0.49972874, 0.30941302, 0.27772993, 0.15990694, 0.33694725,\n",
       "        0.37392885, 0.7576099 , 0.54237423, 0.51062866, 0.61596872,\n",
       "        0.74060881, 1.28500176, 2.0450639 , 1.4549422 , 1.8724631 ,\n",
       "        2.42666885, 0.71709523]),\n",
       " 'mean_score_time': array([0.03333573, 0.03415408, 0.03797555, 0.03695617, 0.05056615,\n",
       "        0.02917061, 0.03769326, 0.04031615, 0.03625112, 0.04269409,\n",
       "        0.03748999, 0.04595861, 0.05571384, 0.07241993, 0.0678051 ,\n",
       "        0.05475211, 0.0679255 , 0.06544986, 0.03295627, 0.02769732,\n",
       "        0.03437448, 0.03226652, 0.03213844, 0.02603636, 0.03086586,\n",
       "        0.03520746, 0.03288059, 0.03880949, 0.03113341, 0.03715968,\n",
       "        0.06400995, 0.06356549, 0.06666746, 0.07528343, 0.07813663,\n",
       "        0.06453047, 0.04648104, 0.02543769, 0.03649125, 0.02806573,\n",
       "        0.0294261 , 0.0295805 , 0.03522911, 0.03742304, 0.04550571,\n",
       "        0.03784313, 0.04369035, 0.04223313, 0.06012392, 0.06877313,\n",
       "        0.06280799, 0.06319175, 0.06543083, 0.05987453, 0.02690935,\n",
       "        0.03051643, 0.03824887, 0.04094772, 0.03210864, 0.0377583 ,\n",
       "        0.03040705, 0.03564925, 0.0318471 , 0.031179  , 0.03651171,\n",
       "        0.04679317, 0.11526723, 0.06885576, 0.08056903, 0.06748142,\n",
       "        0.07048755, 0.05033793]),\n",
       " 'std_score_time': array([0.00707115, 0.01288885, 0.00870463, 0.01102411, 0.01573081,\n",
       "        0.00782672, 0.0027618 , 0.01284867, 0.00643642, 0.01328818,\n",
       "        0.00673373, 0.01745199, 0.00720768, 0.01351393, 0.00852726,\n",
       "        0.00430062, 0.01602823, 0.01104809, 0.012753  , 0.00436249,\n",
       "        0.01438232, 0.00523628, 0.00930428, 0.0023179 , 0.00209568,\n",
       "        0.00796707, 0.00475542, 0.01309903, 0.00374201, 0.00985202,\n",
       "        0.01077761, 0.02652653, 0.01762887, 0.02600505, 0.03506131,\n",
       "        0.01073133, 0.01943343, 0.00282177, 0.01772009, 0.00323791,\n",
       "        0.00567191, 0.0043249 , 0.00479429, 0.00883297, 0.0173372 ,\n",
       "        0.00532464, 0.01099954, 0.01481274, 0.01012713, 0.00667213,\n",
       "        0.01135438, 0.01448986, 0.0108915 , 0.00626132, 0.00235724,\n",
       "        0.01101879, 0.01011564, 0.02924512, 0.0108403 , 0.0121487 ,\n",
       "        0.00310823, 0.00641017, 0.00418989, 0.00265365, 0.00396016,\n",
       "        0.02305434, 0.06637103, 0.01871903, 0.021755  , 0.01290906,\n",
       "        0.01211285, 0.00502716]),\n",
       " 'param_colsample_bytree': masked_array(data=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
       "                    1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
       "                    1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
       "                    1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[50, 50, 50, 50, 50, 50, 100, 100, 100, 100, 100, 100,\n",
       "                    300, 300, 300, 300, 300, 300, 50, 50, 50, 50, 50, 50,\n",
       "                    100, 100, 100, 100, 100, 100, 300, 300, 300, 300, 300,\n",
       "                    300, 50, 50, 50, 50, 50, 50, 100, 100, 100, 100, 100,\n",
       "                    100, 300, 300, 300, 300, 300, 300, 50, 50, 50, 50, 50,\n",
       "                    50, 100, 100, 100, 100, 100, 100, 300, 300, 300, 300,\n",
       "                    300, 300],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_scale_pos_weight': masked_array(data=[1, 1, 5, 5, 10, 10, 1, 1, 5, 5, 10, 10, 1, 1, 5, 5, 10,\n",
       "                    10, 1, 1, 5, 5, 10, 10, 1, 1, 5, 5, 10, 10, 1, 1, 5, 5,\n",
       "                    10, 10, 1, 1, 5, 5, 10, 10, 1, 1, 5, 5, 10, 10, 1, 1,\n",
       "                    5, 5, 10, 10, 1, 1, 5, 5, 10, 10, 1, 1, 5, 5, 10, 10,\n",
       "                    1, 1, 5, 5, 10, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_subsample': masked_array(data=[0.5, 0.8, 0.5, 0.8, 0.5, 0.8, 0.5, 0.8, 0.5, 0.8, 0.5,\n",
       "                    0.8, 0.5, 0.8, 0.5, 0.8, 0.5, 0.8, 0.5, 0.8, 0.5, 0.8,\n",
       "                    0.5, 0.8, 0.5, 0.8, 0.5, 0.8, 0.5, 0.8, 0.5, 0.8, 0.5,\n",
       "                    0.8, 0.5, 0.8, 0.5, 0.8, 0.5, 0.8, 0.5, 0.8, 0.5, 0.8,\n",
       "                    0.5, 0.8, 0.5, 0.8, 0.5, 0.8, 0.5, 0.8, 0.5, 0.8, 0.5,\n",
       "                    0.8, 0.5, 0.8, 0.5, 0.8, 0.5, 0.8, 0.5, 0.8, 0.5, 0.8,\n",
       "                    0.5, 0.8, 0.5, 0.8, 0.5, 0.8],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'scale_pos_weight': 1,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'scale_pos_weight': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'scale_pos_weight': 5,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'scale_pos_weight': 5,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'scale_pos_weight': 10,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'scale_pos_weight': 10,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'scale_pos_weight': 1,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'scale_pos_weight': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'scale_pos_weight': 5,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'scale_pos_weight': 5,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'scale_pos_weight': 10,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'scale_pos_weight': 10,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 300,\n",
       "   'scale_pos_weight': 1,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 300,\n",
       "   'scale_pos_weight': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 300,\n",
       "   'scale_pos_weight': 5,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 300,\n",
       "   'scale_pos_weight': 5,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 300,\n",
       "   'scale_pos_weight': 10,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 300,\n",
       "   'scale_pos_weight': 10,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'scale_pos_weight': 1,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'scale_pos_weight': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'scale_pos_weight': 5,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'scale_pos_weight': 5,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'scale_pos_weight': 10,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'scale_pos_weight': 10,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'scale_pos_weight': 1,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'scale_pos_weight': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'scale_pos_weight': 5,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'scale_pos_weight': 5,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'scale_pos_weight': 10,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'scale_pos_weight': 10,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 300,\n",
       "   'scale_pos_weight': 1,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 300,\n",
       "   'scale_pos_weight': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 300,\n",
       "   'scale_pos_weight': 5,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 300,\n",
       "   'scale_pos_weight': 5,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 300,\n",
       "   'scale_pos_weight': 10,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 300,\n",
       "   'scale_pos_weight': 10,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'scale_pos_weight': 1,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'scale_pos_weight': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'scale_pos_weight': 5,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'scale_pos_weight': 5,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'scale_pos_weight': 10,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 50,\n",
       "   'scale_pos_weight': 10,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'scale_pos_weight': 1,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'scale_pos_weight': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'scale_pos_weight': 5,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'scale_pos_weight': 5,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'scale_pos_weight': 10,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 100,\n",
       "   'scale_pos_weight': 10,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 300,\n",
       "   'scale_pos_weight': 1,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 300,\n",
       "   'scale_pos_weight': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 300,\n",
       "   'scale_pos_weight': 5,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 300,\n",
       "   'scale_pos_weight': 5,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 300,\n",
       "   'scale_pos_weight': 10,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_estimators': 300,\n",
       "   'scale_pos_weight': 10,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'scale_pos_weight': 1,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'scale_pos_weight': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'scale_pos_weight': 5,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'scale_pos_weight': 5,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'scale_pos_weight': 10,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 50,\n",
       "   'scale_pos_weight': 10,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'scale_pos_weight': 1,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'scale_pos_weight': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'scale_pos_weight': 5,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'scale_pos_weight': 5,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'scale_pos_weight': 10,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'scale_pos_weight': 10,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 300,\n",
       "   'scale_pos_weight': 1,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 300,\n",
       "   'scale_pos_weight': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 300,\n",
       "   'scale_pos_weight': 5,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 300,\n",
       "   'scale_pos_weight': 5,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 300,\n",
       "   'scale_pos_weight': 10,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 300,\n",
       "   'scale_pos_weight': 10,\n",
       "   'subsample': 0.8}],\n",
       " 'split0_test_score': array([0.86755556, 0.86222222, 0.82133333, 0.81866667, 0.80533333,\n",
       "        0.79466667, 0.87022222, 0.86133333, 0.82133333, 0.81955556,\n",
       "        0.808     , 0.79555556, 0.86577778, 0.86311111, 0.82844444,\n",
       "        0.82844444, 0.81777778, 0.82311111, 0.85155556, 0.85155556,\n",
       "        0.83644444, 0.82844444, 0.82577778, 0.82755556, 0.85066667,\n",
       "        0.85066667, 0.856     , 0.84177778, 0.83466667, 0.83555556,\n",
       "        0.848     , 0.85244444, 0.85688889, 0.84177778, 0.84088889,\n",
       "        0.84711111, 0.85511111, 0.85066667, 0.82044444, 0.81422222,\n",
       "        0.80088889, 0.79733333, 0.85511111, 0.85866667, 0.82488889,\n",
       "        0.81777778, 0.79911111, 0.80444444, 0.86222222, 0.86488889,\n",
       "        0.82577778, 0.82488889, 0.816     , 0.82133333, 0.85866667,\n",
       "        0.85422222, 0.82666667, 0.832     , 0.82755556, 0.82222222,\n",
       "        0.84622222, 0.85422222, 0.83644444, 0.83733333, 0.82666667,\n",
       "        0.83022222, 0.85422222, 0.85066667, 0.84711111, 0.84266667,\n",
       "        0.83822222, 0.84088889]),\n",
       " 'split1_test_score': array([0.85244444, 0.848     , 0.82577778, 0.82133333, 0.79822222,\n",
       "        0.79111111, 0.84444444, 0.84711111, 0.82755556, 0.82844444,\n",
       "        0.80177778, 0.79733333, 0.84711111, 0.85066667, 0.83022222,\n",
       "        0.83022222, 0.808     , 0.81066667, 0.85333333, 0.84533333,\n",
       "        0.83466667, 0.83644444, 0.81688889, 0.81955556, 0.85066667,\n",
       "        0.84622222, 0.83555556, 0.84177778, 0.81955556, 0.83022222,\n",
       "        0.85155556, 0.84888889, 0.83822222, 0.84      , 0.82844444,\n",
       "        0.82933333, 0.84355556, 0.83644444, 0.82577778, 0.81955556,\n",
       "        0.80444444, 0.79555556, 0.84711111, 0.84177778, 0.824     ,\n",
       "        0.82222222, 0.80266667, 0.80355556, 0.848     , 0.84355556,\n",
       "        0.832     , 0.82933333, 0.81333333, 0.81155556, 0.84622222,\n",
       "        0.84888889, 0.82577778, 0.84355556, 0.81511111, 0.81955556,\n",
       "        0.83911111, 0.84711111, 0.82933333, 0.83733333, 0.82133333,\n",
       "        0.82577778, 0.83822222, 0.84177778, 0.83555556, 0.832     ,\n",
       "        0.84088889, 0.83288889]),\n",
       " 'split2_test_score': array([0.85333333, 0.85066667, 0.816     , 0.80888889, 0.79644444,\n",
       "        0.784     , 0.84977778, 0.84977778, 0.81777778, 0.81777778,\n",
       "        0.79288889, 0.78933333, 0.85955556, 0.86044444, 0.82844444,\n",
       "        0.81866667, 0.79733333, 0.79822222, 0.85777778, 0.84355556,\n",
       "        0.83111111, 0.832     , 0.80977778, 0.81333333, 0.84711111,\n",
       "        0.84444444, 0.83466667, 0.83733333, 0.824     , 0.82755556,\n",
       "        0.84977778, 0.84622222, 0.84444444, 0.848     , 0.84355556,\n",
       "        0.84355556, 0.85511111, 0.85244444, 0.80444444, 0.79911111,\n",
       "        0.78311111, 0.784     , 0.85422222, 0.86044444, 0.80977778,\n",
       "        0.80266667, 0.78933333, 0.78577778, 0.86222222, 0.85422222,\n",
       "        0.82222222, 0.81777778, 0.80088889, 0.80355556, 0.84888889,\n",
       "        0.85955556, 0.82755556, 0.82666667, 0.81333333, 0.81511111,\n",
       "        0.84444444, 0.86044444, 0.84266667, 0.83644444, 0.832     ,\n",
       "        0.83377778, 0.84888889, 0.85688889, 0.84888889, 0.84711111,\n",
       "        0.84977778, 0.84266667]),\n",
       " 'split3_test_score': array([0.84088889, 0.83822222, 0.80088889, 0.80622222, 0.78488889,\n",
       "        0.77955556, 0.84      , 0.83644444, 0.80355556, 0.80444444,\n",
       "        0.78577778, 0.78311111, 0.84444444, 0.84444444, 0.808     ,\n",
       "        0.80888889, 0.79644444, 0.79377778, 0.84444444, 0.83644444,\n",
       "        0.81155556, 0.81155556, 0.79911111, 0.80177778, 0.84444444,\n",
       "        0.84355556, 0.82133333, 0.824     , 0.81333333, 0.81511111,\n",
       "        0.848     , 0.85155556, 0.83644444, 0.83911111, 0.82755556,\n",
       "        0.83022222, 0.83911111, 0.83288889, 0.79288889, 0.79288889,\n",
       "        0.76888889, 0.77422222, 0.84088889, 0.83644444, 0.79466667,\n",
       "        0.79822222, 0.77422222, 0.77688889, 0.84444444, 0.84      ,\n",
       "        0.80266667, 0.80088889, 0.78755556, 0.79111111, 0.84266667,\n",
       "        0.84533333, 0.824     , 0.81155556, 0.78844444, 0.79911111,\n",
       "        0.83555556, 0.83911111, 0.83288889, 0.82222222, 0.81422222,\n",
       "        0.81244444, 0.84      , 0.84      , 0.84622222, 0.84355556,\n",
       "        0.83111111, 0.82844444]),\n",
       " 'split4_test_score': array([0.86209964, 0.863879  , 0.82918149, 0.82295374, 0.78825623,\n",
       "        0.78202847, 0.87188612, 0.86565836, 0.82829181, 0.82740214,\n",
       "        0.79092527, 0.79181495, 0.8772242 , 0.87455516, 0.83185053,\n",
       "        0.83007117, 0.80960854, 0.81405694, 0.8683274 , 0.87188612,\n",
       "        0.84697509, 0.83807829, 0.82384342, 0.82206406, 0.8772242 ,\n",
       "        0.86654804, 0.84608541, 0.84964413, 0.83451957, 0.83896797,\n",
       "        0.8683274 , 0.86298932, 0.85587189, 0.863879  , 0.85231317,\n",
       "        0.86565836, 0.85676157, 0.86120996, 0.81850534, 0.81672598,\n",
       "        0.79359431, 0.79270463, 0.8594306 , 0.863879  , 0.82384342,\n",
       "        0.82206406, 0.7980427 , 0.79537367, 0.8683274 , 0.8727758 ,\n",
       "        0.83274021, 0.83451957, 0.81761566, 0.81494662, 0.87188612,\n",
       "        0.87099644, 0.83807829, 0.84163701, 0.81761566, 0.81939502,\n",
       "        0.87099644, 0.87188612, 0.84341637, 0.85587189, 0.83451957,\n",
       "        0.83096085, 0.86565836, 0.87633452, 0.86032028, 0.85765125,\n",
       "        0.85142349, 0.86565836]),\n",
       " 'mean_test_score': array([0.85526437, 0.85259802, 0.8186363 , 0.81561297, 0.79462902,\n",
       "        0.78627236, 0.85526611, 0.85206501, 0.81970281, 0.81952487,\n",
       "        0.79587394, 0.79142966, 0.85882262, 0.85864437, 0.82539233,\n",
       "        0.82325868, 0.80583282, 0.80796694, 0.8550877 , 0.849755  ,\n",
       "        0.83215057, 0.82930455, 0.81507979, 0.81685726, 0.85402262,\n",
       "        0.85028739, 0.83872819, 0.8389066 , 0.82521503, 0.82948248,\n",
       "        0.85313215, 0.85242009, 0.84637438, 0.84655358, 0.83855152,\n",
       "        0.84317612, 0.84993009, 0.84673088, 0.81241218, 0.80850075,\n",
       "        0.79018553, 0.78876315, 0.85135279, 0.85224247, 0.81543535,\n",
       "        0.81259059, 0.79267521, 0.79320807, 0.85704326, 0.85508849,\n",
       "        0.82308138, 0.82148169, 0.80707869, 0.80850043, 0.85366611,\n",
       "        0.85579929, 0.82841566, 0.83108296, 0.81241202, 0.815079  ,\n",
       "        0.84726595, 0.854555  , 0.83694994, 0.83784104, 0.82574836,\n",
       "        0.82663662, 0.84939834, 0.85313357, 0.84761961, 0.84459692,\n",
       "        0.8422847 , 0.84210945]),\n",
       " 'std_test_score': array([0.00912282, 0.0095018 , 0.00991359, 0.0067725 , 0.00729756,\n",
       "        0.00569504, 0.01326796, 0.01043509, 0.00897257, 0.0086265 ,\n",
       "        0.00796529, 0.00501234, 0.0120948 , 0.01040795, 0.00878818,\n",
       "        0.00835907, 0.00802518, 0.01067721, 0.00789125, 0.012068  ,\n",
       "        0.01157385, 0.00949725, 0.00977375, 0.00881651, 0.0118351 ,\n",
       "        0.00849159, 0.0116755 , 0.0084435 , 0.00837363, 0.0082177 ,\n",
       "        0.00771117, 0.00571559, 0.00859702, 0.00920229, 0.00941223,\n",
       "        0.01327031, 0.00718387, 0.01053746, 0.01204099, 0.01053085,\n",
       "        0.01290808, 0.00859356, 0.00655888, 0.01098216, 0.01180478,\n",
       "        0.01014254, 0.0102151 , 0.01057867, 0.00918135, 0.01241217,\n",
       "        0.01093256, 0.0116707 , 0.01139477, 0.01041548, 0.01054699,\n",
       "        0.00899822, 0.00497236, 0.01156389, 0.01295363, 0.00830262,\n",
       "        0.01245649, 0.01121686, 0.00546363, 0.01069135, 0.00733764,\n",
       "        0.00754595, 0.01001151, 0.01311424, 0.00788252, 0.00824899,\n",
       "        0.00752283, 0.01286936]),\n",
       " 'rank_test_score': array([ 6, 14, 51, 53, 66, 72,  5, 17, 49, 50, 65, 69,  1,  2, 44, 46, 64,\n",
       "        62,  8, 21, 37, 40, 55, 52, 10, 19, 33, 32, 45, 39, 13, 15, 27, 26,\n",
       "        34, 29, 20, 25, 58, 60, 70, 71, 18, 16, 54, 57, 68, 67,  3,  7, 47,\n",
       "        48, 63, 61, 11,  4, 41, 38, 59, 56, 24,  9, 36, 35, 43, 42, 22, 12,\n",
       "        23, 28, 30, 31])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.cv_results_\n",
    "# print(grid_search.best_params_)\n",
    "# print(grid_search.best_estimator_)\n",
    "# print(grid_search.best_score_)\n",
    "# print(grid_search.scorer_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0c04a2-8992-458d-b1c5-9fa1f3bd5000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
